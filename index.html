<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AI Emotion Recognition - AI & Robotics Club</title>

  <!-- React & Babel -->
  <script crossorigin src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
  <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
  <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>

  <!-- Tailwind CSS -->
  <script src="https://cdn.tailwindcss.com"></script>

  <!-- Face API -->
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>

  <style>
    @keyframes pulse {
      0%, 100% { opacity: 1; }
      50% { opacity: 0.5; }
    }
    .animate-pulse {
      animation: pulse 2s cubic-bezier(0.4, 0, 0.6, 1) infinite;
    }
  </style>
</head>
<body class="bg-black text-white">
  <div id="root"></div>

  <script type="text/babel">
    const { useState, useRef, useEffect } = React;

    const EmotionQuoteApp = () => {
      const [emotion, setEmotion] = useState('neutral');
      const [quote, setQuote] = useState('');
      const [isWebcamActive, setIsWebcamActive] = useState(false);
      const [error, setError] = useState('');
      const videoRef = useRef(null);
      const streamRef = useRef(null);

      const quotes = {
        happy: [
          "Your smile is contagious! Keep spreading that joy! ðŸ˜Š",
          "Happiness looks beautiful on you! âœ¨",
          "The world is brighter because of your smile! ðŸŒŸ",
          "Your positive energy is inspiring! Keep shining! â˜€ï¸",
          "Joy is the best makeupâ€”you're wearing it perfectly! ðŸ’«"
        ],
        sad: [
          "Every storm runs out of rain. This too shall pass. ðŸŒˆ",
          "You are stronger than you know. Better days are coming. ðŸ’ª",
          "It's okay to not be okay. Take your time, you've got this. ðŸŒ¸",
          "Tough times don't last, but tough people do. ðŸŒ»",
          "The sun will rise again, and so will you. ðŸŒ…"
        ],
        mad: [
          "Take a deep breath. You have the power to choose peace. ðŸŒŠ",
          "Your calm mind is your superpower. ðŸ§˜",
          "This feeling is temporary. Choose peace. â˜®ï¸",
          "Let it go. You deserve happiness. ðŸ•Šï¸",
          "Breathe in calm, breathe out frustration. ðŸŒ¬ï¸"
        ],
        neutral: [
          "You are exactly where you need to be right now. ðŸŒŸ",
          "Every moment is a fresh beginning. â³",
          "Your potential is limitless. ðŸ’Ž",
          "Today is full of possibilities. ðŸŒˆ",
          "You are capable of amazing things! ðŸ’Ž"
        ]
      };

      const emotionColors = {
        happy: 'from-cyan-400 via-blue-500 to-purple-600',
        sad: 'from-blue-600 via-indigo-700 to-purple-800',
        mad: 'from-red-500 via-pink-600 to-purple-700',
        neutral: 'from-indigo-500 via-purple-600 to-pink-600'
      };

      // ðŸ§  Load models
      useEffect(() => {
        const loadModels = async () => {
          try {
            await faceapi.nets.tinyFaceDetector.loadFromUri('/model');
            await faceapi.nets.faceExpressionNet.loadFromUri('/model');
            console.log("Models loaded âœ…");
          } catch (err) {
            console.error("Error loading models:", err);
          }
        };
        loadModels();
      }, []);

      useEffect(() => {
        setQuote(quotes[emotion][Math.floor(Math.random() * quotes[emotion].length)]);
      }, [emotion]);

      const startWebcam = async () => {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' } });
          if (videoRef.current) {
            videoRef.current.srcObject = stream;
            streamRef.current = stream;
            setIsWebcamActive(true);
            setError('');
            detectEmotions();
          }
        } catch (err) {
          setError('Unable to access webcam. Please grant camera permissions.');
          console.error('Webcam error:', err);
        }
      };

      const stopWebcam = () => {
        if (streamRef.current) {
          streamRef.current.getTracks().forEach(track => track.stop());
          streamRef.current = null;
        }
        if (videoRef.current) videoRef.current.srcObject = null;
        setIsWebcamActive(false);
      };

      // ðŸŽ¯ Real detection
      const detectEmotions = async () => {
        const interval = setInterval(async () => {
          if (!videoRef.current || !streamRef.current) {
            clearInterval(interval);
            return;
          }
          try {
            const detections = await faceapi
              .detectSingleFace(videoRef.current, new faceapi.TinyFaceDetectorOptions())
              .withFaceExpressions();

            if (detections && detections.expressions) {
              const detectedEmotion = Object.keys(detections.expressions)
                .reduce((a, b) => detections.expressions[a] > detections.expressions[b] ? a : b);
              setEmotion(detectedEmotion);
            }
          } catch (err) {
            console.error("Detection error:", err);
          }
